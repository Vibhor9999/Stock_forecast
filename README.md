# Stock_forecast
Store Clustering Dashboard
This repository contains a Python-based solution for clustering store-level data, visualizing the clusters, and deploying the results via a simple web application using Streamlit.

Problem Statement
The core task involves applying K-Means Clustering (or an equivalent method) to store-level data. The solution aims to creatively score the data, develop meaningful cluster features, and present the results in an easily deployable graphical user interface.

Features
Data Clustering: Utilizes K-Means Clustering to group stores based on their features.

Dimensionality Reduction: Employs Principal Component Analysis (PCA) to reduce data dimensionality for visualization.

Interactive Visualization: Displays clustered data and cluster characteristics using seaborn and matplotlib plots.

Web User Interface: A Streamlit application provides an interactive dashboard to view the clustered data and visualizations.

Model Persistence: The trained K-Means model is saved for future use or deployment.

Project Structure
.
├── app.py                  # Streamlit web application
├── requirements.txt        # Python dependencies
├── README.md               # Project overview and setup instructions
├── store_clusters.csv      # Output: Clustered data (generated after running clustering script)
└── kmeans_model.pkl        # Output: Trained KMeans model (generated after running clustering script)

Setup Instructions
To set up and run this project locally, follow these steps:

Prerequisites
Python 3.7+

pip (Python package installer)

1. Clone the Repository
git clone <your-repo-url>
cd <your-repo-name>

2. Install Dependencies
It's highly recommended to use a virtual environment.

python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
pip install -r requirements.txt

3. Data Preparation
The project expects a store_clusters.csv file, which contains your processed data along with the assigned cluster labels and PCA components (pca_x, pca_y). This file is generated by the clustering script (which you would have run in your Colab environment).

Important: Ensure you have the store_clusters.csv file and kmeans_model.pkl in the same directory as app.py. If you need to regenerate them, you'll need to run your data processing and clustering script (from your Colab notebook) first.

4. Run the Streamlit Application
Once the dependencies are installed and the store_clusters.csv file is available, you can run the Streamlit application:

streamlit run app.py

This command will open the Streamlit dashboard in your web browser, typically at http://localhost:8501.

Data Analysis Key Findings (from your provided summary)
The dataset contains 4313 store entries with features including sales, cost, forecast, and PCA components (pca_x, pca_y), along with a pre-assigned cluster label.

The unit_cost_amount column is entirely empty and does not contain any usable data.

Store clusters have been visualized using PCA components, showing distinct groupings of stores based on their features.

The clustered data and the KMeans model used for clustering were successfully saved to CSV and pickle files, respectively, for potential future use or deployment.

A basic Streamlit application (app.py) was successfully created to display the clustered data and the cluster visualization.

Insights or Next Steps (from your provided summary)
The lack of unit_cost_amount data might impact analyses requiring cost information; consider if this data can be sourced or imputed.

Further analysis of cluster characteristics (e.g., average sales, common product categories per cluster) would provide deeper business insights.

The Streamlit UI can be enhanced with more interactive elements and detailed cluster summaries.
